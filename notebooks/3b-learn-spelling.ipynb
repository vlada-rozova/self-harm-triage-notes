{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a405c693",
   "metadata": {},
   "source": [
    "# Create a dictionary of misspellings\n",
    "\n",
    "This notebook parses the whole dataset and adds to an empty dict every token starting with an alpha that is not known to the vocabulary. After that, for each misspelled word a corrected version is found using pyspellchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caeaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "import json\n",
    "\n",
    "# Project imports\n",
    "from self_harm_triage_notes.config import interim_data_dir, spell_corr_dir\n",
    "from self_harm_triage_notes.text_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED vocabulary\n",
    "vocab_filename = \"rmh_2012_2017_dev_amt6\"\n",
    "\n",
    "# Dataset used for learning\n",
    "tokenized_data_filename = \"rmh_2012_2017_dev_amt6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27855e1b",
   "metadata": {},
   "source": [
    "### Load pre-processed and tokenised training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a887f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(interim_data_dir / (tokenized_data_filename + \"_nospellcorr.parquet\"), engine=\"pyarrow\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffcbe3",
   "metadata": {},
   "source": [
    "### Load ED vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ED vocabulary\n",
    "vocab = load_vocab(spell_corr_dir, vocab_filename)\n",
    "\n",
    "# Load ED word frequency list\n",
    "word_list = load_word_list(spell_corr_dir, vocab_filename)\n",
    "\n",
    "# Load the dictionary of corrected misspellings\n",
    "misspelled_dict = load_misspelled_dict(spell_corr_dir, vocab_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75959dbd",
   "metadata": {},
   "source": [
    "### Find tokens unknown to the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be01615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count all valid tokens in the corpus\n",
    "counts = count_tokens(df.tokenized_triage_note, valid=True)\n",
    "# Select tokens unknown to the vocabulary\n",
    "unknown_tokens = {k:v for k,v in counts.items() if k not in vocab}\n",
    "print(\"Detected %d unique tokens unknown to the vocabulary (%d in total).\" % \n",
    "          (len(unknown_tokens), sum(v for v in unknown_tokens.values())))\n",
    "print(\"- %d tokens occur only once.\" % \n",
    "      sum(1 for v in unknown_tokens.values() if v==1))\n",
    "print(\"- %d tokens occur less than 10 times.\" % \n",
    "          sum(1 for v in unknown_tokens.values() if v<10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f251da7",
   "metadata": {},
   "source": [
    "### Attempt to correct spelling in OOV tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9792f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correct_spelling(unknown_tokens, misspelled_dict=None, word_list=None):\n",
    "    \"\"\"\n",
    "    Find a correct spelling for every unknown token either based on an \n",
    "    existing dictionary of misspellings or by running spellchecker. \n",
    "    \"\"\"\n",
    "    if word_list:\n",
    "        # Initialise spellchecker with a custom vocab\n",
    "        spell = SpellChecker(language=None)\n",
    "        spell.word_frequency.load_words(word_list)\n",
    "    else:\n",
    "        spell=None\n",
    "        \n",
    "    known_misspellings = 0\n",
    "    \n",
    "    for token in unknown_tokens.keys():\n",
    "        if misspelled_dict and token in misspelled_dict.keys():\n",
    "            unknown_tokens.update({token : (unknown_tokens[token], misspelled_dict[token])})\n",
    "            known_misspellings += 1\n",
    "        elif spell:\n",
    "            unknown_tokens.update({token : (unknown_tokens[token], spell.correction(token))})\n",
    "        else:\n",
    "            unknown_tokens.update({token : (unknown_tokens[token], None)})\n",
    "            \n",
    "    print(\"Found a spelling correction for %d words.\" % sum(1 for v in unknown_tokens.values() if v[1]!=None))\n",
    "    print(\"Out of those, %d were in the existing dictionary of misspellings and the rest are new.\" % \n",
    "          known_misspellings)\n",
    "    \n",
    "    return unknown_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_tokens = find_correct_spelling(unknown_tokens, misspelled_dict=misspelled_dict, word_list=word_list)\n",
    "# unknown_tokens = find_correct_spelling({k:v for k,v in unknown_tokens.items() if v>=100}, word_list=word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecfbd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(unknown_tokens.items(),  key=lambda item: item[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f71850",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(unknown_tokens, \n",
    "                       orient='index', \n",
    "                       columns=('phrase', 'count')\n",
    "                      ).to_csv(spell_corr_dir / \"unknown_tokens.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc466a2",
   "metadata": {},
   "source": [
    "### Overwrite spelling corrections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b728ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load reviewed corrections\n",
    "corrections = pd.read_csv(spell_corr_dir / \"unknown_tokens_reviewed.csv\")\n",
    "corrections.columns = ['phrase', 'count', 'correction']\n",
    "corrections.fillna({'correction': \"\"}, inplace=True)\n",
    "corrections = corrections.set_index('phrase').correction.to_dict()\n",
    "\n",
    "for k,v in corrections.items():\n",
    "    if v==\"\":\n",
    "        corrections[k] = None\n",
    "corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dictionary of misspellings\n",
    "for k in unknown_tokens:\n",
    "    if k in corrections:\n",
    "        unknown_tokens[k] = (unknown_tokens[k][0], corrections[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfe8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(unknown_tokens.items(),  key=lambda item: item[1][0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def overwirte_correction(token, correction):\n",
    "#     count = unknown_tokens[token][0]\n",
    "#     unknown_tokens.update({token : (count, correction)})\n",
    "    \n",
    "# overwirte_correction(\"incont\", \"incontinent\")\n",
    "# overwirte_correction(\"hyperchol\", \"hypercholesterolemia\")\n",
    "# overwirte_correction(\"edmo\", \"ecmo\")\n",
    "# overwirte_correction(\"ivabs\", \"abs\")\n",
    "# overwirte_correction(\"intermient\", \"intermittent\")\n",
    "# overwirte_correction(\"intermit\", \"intermittent\")\n",
    "# overwirte_correction(\"ivab\", \"abs\")\n",
    "# overwirte_correction(\"bilate\", \"bilateral\")\n",
    "# overwirte_correction(\"symp\", \"symptoms\")\n",
    "# overwirte_correction(\"palpn\", \"palpitation\")\n",
    "# overwirte_correction(\"sympt\", \"symptoms\")\n",
    "# overwirte_correction(\"excas\", \"exacerbation\")\n",
    "# overwirte_correction(\"monc\", \"medical oncology\")\n",
    "# overwirte_correction(\"polypharm\", \"polypharmacy\")\n",
    "# overwirte_correction(\"pmac\", \"pmcc\")\n",
    "# overwirte_correction(\"ethol\", \"etoh\")\n",
    "# overwirte_correction(\"cholesectomy\", \"cholecystectomy\")\n",
    "# overwirte_correction(\"autoinfusion\", \"auto infusion\")\n",
    "# overwirte_correction(\"autoinfused\", \"auto infused\")\n",
    "# overwirte_correction(\"boxhill\", \"box hill\")\n",
    "# overwirte_correction(\"swollening\", \"swelling\")\n",
    "# overwirte_correction(\"vascuarly\", \"vascular\")\n",
    "# overwirte_correction(\"neckstiffness\", \"neck stiffness\")\n",
    "# overwirte_correction(\"suddenonset\", \"sudden onset\")\n",
    "# overwirte_correction(\"motorsensory\", \"motor sensory\")\n",
    "# overwirte_correction(\"neurovascally\", \"neurovascularly\")\n",
    "# overwirte_correction(\"interhospital\", \"inter hospital\")\n",
    "# overwirte_correction(\"antiinflammatories\", \"antiinflammatory\")\n",
    "# overwirte_correction(\"hardcollar\", \"hard collar\")\n",
    "# overwirte_correction(\"dirroreah\", \"diarrhoea\")\n",
    "# overwirte_correction(\"petermac\", \"pmcc\")\n",
    "# overwirte_correction(\"weighbare\", \"weightbear\")\n",
    "# overwirte_correction(\"bodyache\", \"body ache\")\n",
    "# overwirte_correction(\"spinabifida\", \"spina bifida\")\n",
    "# overwirte_correction(\"painrelief\", \"pain relief\")\n",
    "# overwirte_correction(\"hypercholest\", \"hypercholesterol\")\n",
    "# overwirte_correction(\"triagephx\", \"triage phx\")\n",
    "# overwirte_correction(\"aspirin300\", \"aspirin 300\")\n",
    "# overwirte_correction(\"sorethroat\", \"sore throat\")\n",
    "# overwirte_correction(\"haemoserrous\", \"haemoserous\")\n",
    "# overwirte_correction(\"interminant\", \"intermittent\")\n",
    "# overwirte_correction(\"apperiants\", \"aperients\")\n",
    "# overwirte_correction(\"bodyaches\", \"body aches\")\n",
    "# overwirte_correction(\"facestrike\", \"face strike\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a01269",
   "metadata": {},
   "source": [
    "### Corrected misspellings and  OOV tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_misspelled_oov(unknown_tokens):\n",
    "    \"\"\"\n",
    "    Separate unknown tokens into corrected and out-of-vocabulary tokens. \n",
    "    \"\"\"\n",
    "    misspelled = {k:v[1] for k,v in unknown_tokens.items() if v[1]!=None}\n",
    "    print(\"Corrected the spelling of %d words.\" % len(misspelled))\n",
    "    \n",
    "    oov = {k:v for k,v in unknown_tokens.items() if v[1]==None}\n",
    "    print(\"Failed to correct spelling of %d words.\" % len(oov))\n",
    "    print(\"- %d words appear in the corpus only once.\" % \n",
    "          sum(1 for v in oov.values() if v[0]==1))\n",
    "    print(\"- %d words appear in the corpus less than 10 times.\" % \n",
    "          sum(1 for v in oov.values() if v[0]<10))\n",
    "    \n",
    "    return misspelled, oov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5beaeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled, oov = split_misspelled_oov(unknown_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd565f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(spell_corr_dir / (tokenized_data_filename + \"_misspelled_dict.json\"), 'w') as f:\n",
    "    json.dump(misspelled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8e978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-harm-triage-notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
