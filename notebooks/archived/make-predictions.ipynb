{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from devutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED vocabulary\n",
    "vocab_filename = \"rmh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Dictionary of misspellings\n",
    "spell_filename = \"rmh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Classifier and threshold\n",
    "model_filename = \"calibrated_lgbm_rmh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Dataset used for analysis\n",
    "unseen_data_filename = \"lvrh_2012_2022\" # rmh_2012_2017_test, rmh_2018_2022, lvrh_2012_2022\n",
    "\n",
    "normalise = False\n",
    "correct = False\n",
    "mode = 'eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ED vocabulary\n",
    "vocab = load_vocab(vocab_filename)\n",
    "\n",
    "# Load the dictionary of corrected misspellings\n",
    "misspelled_dict = load_misspelled_dict(spell_filename)\n",
    "    \n",
    "# Load a pre-trained model and threshold\n",
    "model, thresh = load_model(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if normalise:\n",
    "    # All steps of triage note normalisation\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \".csv\", \n",
    "                     converters={'triage_note': str})\n",
    "    unseen_data_filename = unseen_data_filename.replace('_cleaned', '')\n",
    "    print_stats(df)\n",
    "    count_tokens(df.triage_note)\n",
    "\n",
    "    # Pre-processing\n",
    "    df['preprocessed_triage_note'] = df.triage_note.apply(preprocess)\n",
    "    count_tokens(df.preprocessed_triage_note)\n",
    "    \n",
    "    # Create tokenised text\n",
    "    df['tokenized_triage_note'] = tokenize_step1(df.preprocessed_triage_note)\n",
    "    count_tokens(df.tokenized_triage_note)\n",
    "    \n",
    "    # Re-tokenise text\n",
    "    df.tokenized_triage_note = tokenize_step2(df.tokenized_triage_note, vocab)\n",
    "    count_tokens(df.tokenized_triage_note)\n",
    "    \n",
    "    # Correct spelling mistakes\n",
    "    df['corrected_triage_note'] = df.tokenized_triage_note.apply(spelling_correction, \n",
    "                                                                 misspelled_dict=misspelled_dict)\n",
    "    count_tokens(df.corrected_triage_note)\n",
    "    \n",
    "    # Replace slang for medications\n",
    "    df['normalised_triage_note'] = replace_slang(df.corrected_triage_note)\n",
    "    count_tokens(df.normalised_triage_note)\n",
    "    \n",
    "    # Extract features\n",
    "    df['entities'] = df.normalised_triage_note.apply(extract_features)\n",
    "    count_tokens(df.entities)\n",
    "    \n",
    "elif correct:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_nospellcorr.csv\", \n",
    "                     converters={'tokenized_triage_note': str})\n",
    "    count_tokens(df.tokenized_triage_note)\n",
    "    \n",
    "    # Correct spelling mistakes\n",
    "    df['corrected_triage_note'] = df.tokenized_triage_note.apply(spelling_correction, \n",
    "                                                                 misspelled_dict=misspelled_dict)\n",
    "    count_tokens(df.corrected_triage_note)\n",
    "    \n",
    "    # Replace slang for medications\n",
    "    df['normalised_triage_note'] = replace_slang(df.corrected_triage_note)\n",
    "    count_tokens(df.normalised_triage_note)\n",
    "    \n",
    "    # Extract features\n",
    "    df['entities'] = df.normalised_triage_note.apply(extract_features)\n",
    "    count_tokens(df.entities)\n",
    "    \n",
    "else:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_normalised.csv\", \n",
    "                     converters={'triage_note': str, \n",
    "                                 'preprocessed_triage_note': str, \n",
    "                                 'tokenized_triage_note': str, \n",
    "                                 'corrected_triage_note': str, \n",
    "                                 'normalised_triage_note': str,\n",
    "                                 'entities': str})\n",
    "    print_stats(df)\n",
    "    \n",
    "# Define features\n",
    "features='entities'\n",
    "X = df[features]\n",
    "\n",
    "# Make predictions\n",
    "y_proba = model.predict_proba(X)\n",
    "y_proba = y_proba[:,1]\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred = threshold_proba(y_proba, thresh)\n",
    "\n",
    "#  NLP classifier predictions\n",
    "df['probability'] = y_proba\n",
    "df['prediction'] = y_pred\n",
    "\n",
    "if mode == 'eval':\n",
    "    y = df.SH\n",
    "    # Plot curves\n",
    "    plot_curves(y, y_proba, filename=unseen_data_filename)\n",
    "    # Evaluate classification on the whole dataset\n",
    "    evaluate_classification(y, y_pred, filename=unseen_data_filename)\n",
    "else:\n",
    "    print(\"Proportion of labels predicted as positive: %.1f%%\" % \n",
    "          (df.prediction.sum() / df.shape[0] * 100))\n",
    "\n",
    "df.to_csv(\"../datasets/\" + unseen_data_filename + \"_predicted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction_class'] = \"TN\"\n",
    "df.loc[(df.SH==1) & (df.prediction==1), 'prediction_class'] = \"TP\"\n",
    "df.loc[(df.SH==1) & (df.prediction==0), 'prediction_class'] = \"FN\"\n",
    "df.loc[(df.SH==0) & (df.prediction==1), 'prediction_class'] = \"FP\"\n",
    "df.prediction_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarter'] = df.arrival_date.dt.to_period('Q')\n",
    "\n",
    "idx = df[df.prediction_class.isin(['FP', 'FN'])].groupby(['quarter', 'prediction_class']).sample(3).index\n",
    "\n",
    "df['for_review'] = 0\n",
    "df.loc[idx, 'for_review'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arrival_date', 'triage_note', \n",
    "        'SH', 'SI', 'AOD_OD', \n",
    "        'probability', 'prediction', 'prediction_class', \n",
    "        'for_review']\n",
    "\n",
    "df[cols].to_csv(\"../datasets/\" + unseen_data_filename + \"_predicted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
