{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714aad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_harm_triage_notes.config import data_interim_dir, data_proc_dir, data_pred_dir, models_dir\n",
    "from self_harm_triage_notes.text_utils import *\n",
    "from self_harm_triage_notes.viz_utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_colwidth = 100\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd9f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename = \"rmh_2012_2017_dev\"\n",
    "# Load selected features\n",
    "with open(models_dir / (data_filename + \"_selected_fts.txt\"), 'r') as f:\n",
    "    selected_features_rmh = f.read().split()\n",
    "len(selected_features_rmh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a89c795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filename = \"lvrh_2012_2022\"\n",
    "# Load selected features\n",
    "with open(models_dir / (data_filename + \"_selected_fts.txt\"), 'r') as f:\n",
    "    selected_features_lvrh = f.read().split()\n",
    "len(selected_features_lvrh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e9f0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdo',\n",
       " 'abilify',\n",
       " 'abscond',\n",
       " 'absconded',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'accom',\n",
       " 'acid',\n",
       " 'acs',\n",
       " 'active',\n",
       " 'addiction',\n",
       " 'adhd',\n",
       " 'adipose',\n",
       " 'admits',\n",
       " 'advil',\n",
       " 'af',\n",
       " 'afebrile',\n",
       " 'affect',\n",
       " 'aggressive',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'alcohol',\n",
       " 'alprazolam',\n",
       " 'altercation',\n",
       " 'ami',\n",
       " 'amitriptyline',\n",
       " 'amounts',\n",
       " 'ams',\n",
       " 'analgesia',\n",
       " 'ane',\n",
       " 'anger',\n",
       " 'ankle',\n",
       " 'antidepressant',\n",
       " 'antidepressants',\n",
       " 'anxiety',\n",
       " 'anymore',\n",
       " 'approx',\n",
       " 'argument',\n",
       " 'argumentative',\n",
       " 'arms',\n",
       " 'arterial',\n",
       " 'assoc',\n",
       " 'associated',\n",
       " 'asylum',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attendance',\n",
       " 'auditory',\n",
       " 'av',\n",
       " 'avanza',\n",
       " 'baclofen',\n",
       " 'balcony',\n",
       " 'bandaged',\n",
       " 'beech',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'behavioural',\n",
       " 'ben',\n",
       " 'bends',\n",
       " 'benzodiazepine',\n",
       " 'benztropine',\n",
       " 'bib',\n",
       " 'bibp',\n",
       " 'bipolar',\n",
       " 'blade',\n",
       " 'blades',\n",
       " 'bleach',\n",
       " 'borderline',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bourbon',\n",
       " 'bowel',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boyfriend',\n",
       " 'bpad',\n",
       " 'bpd',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakup',\n",
       " 'bridge',\n",
       " 'brought',\n",
       " 'bulimia',\n",
       " 'burning',\n",
       " 'butchers',\n",
       " 'butter',\n",
       " 'c/o',\n",
       " 'ca',\n",
       " 'cade',\n",
       " 'caffeine',\n",
       " 'called',\n",
       " 'calm',\n",
       " 'cannabis',\n",
       " 'cans',\n",
       " 'carbon',\n",
       " 'case',\n",
       " 'catt',\n",
       " 'ccf',\n",
       " 'central',\n",
       " 'champagne',\n",
       " 'chest',\n",
       " 'chol',\n",
       " 'citalopram',\n",
       " 'clonazepam',\n",
       " 'clonidine',\n",
       " 'cm',\n",
       " 'cms',\n",
       " 'cocaine',\n",
       " 'codeine',\n",
       " 'codral',\n",
       " 'communication',\n",
       " 'compliant',\n",
       " 'consumed',\n",
       " 'contact',\n",
       " 'cooperative',\n",
       " 'copd',\n",
       " 'cough',\n",
       " 'court',\n",
       " 'cp',\n",
       " 'crisis',\n",
       " 'crying',\n",
       " 'ct',\n",
       " 'cub',\n",
       " 'cubital',\n",
       " 'custody',\n",
       " 'cut',\n",
       " 'cuts',\n",
       " 'cutter',\n",
       " 'cutting',\n",
       " 'cymbalta',\n",
       " 'death',\n",
       " 'decreased',\n",
       " 'deflation',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'dep',\n",
       " 'depressants',\n",
       " 'depressed',\n",
       " 'depression',\n",
       " 'depressive',\n",
       " 'dexamphetamine',\n",
       " 'dial',\n",
       " 'diarrhoea',\n",
       " 'diazepam',\n",
       " 'die',\n",
       " 'difficulty',\n",
       " 'direct',\n",
       " 'disagreement',\n",
       " 'disorder',\n",
       " 'dispute',\n",
       " 'distressed',\n",
       " 'dizziness',\n",
       " 'dm',\n",
       " 'domestic',\n",
       " 'dosage',\n",
       " 'dose',\n",
       " 'doses',\n",
       " 'doxylamine',\n",
       " 'drank',\n",
       " 'drowning',\n",
       " 'drowsiness',\n",
       " 'drowsy',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'ds',\n",
       " 'dsh',\n",
       " 'duloxetine',\n",
       " 'easily',\n",
       " 'ecatt',\n",
       " 'emotional',\n",
       " 'enalapril',\n",
       " 'end',\n",
       " 'endep',\n",
       " 'endone',\n",
       " 'engage',\n",
       " 'engaging',\n",
       " 'epigastric',\n",
       " 'epilim',\n",
       " 'escitalopram',\n",
       " 'etoh',\n",
       " 'ett',\n",
       " 'evasive',\n",
       " 'expressed',\n",
       " 'expressing',\n",
       " 'extra',\n",
       " 'face',\n",
       " 'facial',\n",
       " 'fall',\n",
       " 'febrile',\n",
       " 'fell',\n",
       " 'fever',\n",
       " 'fevers',\n",
       " 'fight',\n",
       " 'finger',\n",
       " 'flank',\n",
       " 'flat',\n",
       " 'flexor',\n",
       " 'fluctuating',\n",
       " 'fluoxetine',\n",
       " 'foot',\n",
       " 'forearm',\n",
       " 'forearms',\n",
       " 'forte',\n",
       " 'forthcoming',\n",
       " 'fracture',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'g',\n",
       " 'gambling',\n",
       " 'gamma',\n",
       " 'gcs',\n",
       " 'generalised',\n",
       " 'girlfriend',\n",
       " 'glass',\n",
       " 'glasses',\n",
       " 'glyceryl',\n",
       " 'gm',\n",
       " 'goodbye',\n",
       " 'gp',\n",
       " 'grams',\n",
       " 'grey',\n",
       " 'gx',\n",
       " 'half',\n",
       " 'hallucinations',\n",
       " 'halm',\n",
       " 'handful',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'happy',\n",
       " 'harm',\n",
       " 'harmed',\n",
       " 'harming',\n",
       " 'head',\n",
       " 'headache',\n",
       " 'headspace',\n",
       " 'headstrike',\n",
       " 'health',\n",
       " 'help',\n",
       " 'heroin',\n",
       " 'hip',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'housemates',\n",
       " 'hs',\n",
       " 'ht',\n",
       " 'htn',\n",
       " 'hurt',\n",
       " 'husband',\n",
       " 'hydrochloric',\n",
       " 'hydroxybutyric',\n",
       " 'ibuprofen',\n",
       " 'ice',\n",
       " 'idea',\n",
       " 'ideation',\n",
       " 'ideations',\n",
       " 'imovane',\n",
       " 'improvement',\n",
       " 'increasing',\n",
       " 'infection',\n",
       " 'infested',\n",
       " 'inflicted',\n",
       " 'information',\n",
       " 'ingested',\n",
       " 'ingesting',\n",
       " 'ingestion',\n",
       " 'injected',\n",
       " 'injury',\n",
       " 'inspiration',\n",
       " 'intended',\n",
       " 'intent',\n",
       " 'intention',\n",
       " 'intentional',\n",
       " 'intentionally',\n",
       " 'intentions',\n",
       " 'intermittent',\n",
       " 'intoxicated',\n",
       " 'intubate',\n",
       " 'ivdu',\n",
       " 'john',\n",
       " 'jump',\n",
       " 'jumped',\n",
       " 'kalma',\n",
       " 'ken',\n",
       " 'key',\n",
       " 'kill',\n",
       " 'kitchen',\n",
       " 'knee',\n",
       " 'knife',\n",
       " 'l',\n",
       " 'lac',\n",
       " 'laceration',\n",
       " 'lacerations',\n",
       " 'lamictal',\n",
       " 'lamotrigine',\n",
       " 'largactil',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'lethargy',\n",
       " 'lexapro',\n",
       " 'life',\n",
       " 'lifeline',\n",
       " 'ligature',\n",
       " 'lighter',\n",
       " 'lithium',\n",
       " 'live',\n",
       " 'lmo',\n",
       " 'loc',\n",
       " 'longer',\n",
       " 'looks',\n",
       " 'lorazepam',\n",
       " 'lovan',\n",
       " 'lower',\n",
       " 'lyrica',\n",
       " 'magic',\n",
       " 'maintaining',\n",
       " 'maintains',\n",
       " 'major',\n",
       " 'making',\n",
       " 'marijuana',\n",
       " 'marks',\n",
       " 'mate',\n",
       " 'mechanical',\n",
       " 'medicating',\n",
       " 'medication',\n",
       " 'medications',\n",
       " 'meds',\n",
       " 'melatonin',\n",
       " 'mental',\n",
       " 'mersyndol',\n",
       " 'message',\n",
       " 'methadone',\n",
       " 'methylated',\n",
       " 'mg',\n",
       " 'mgs',\n",
       " 'mh',\n",
       " 'micardis',\n",
       " 'midazolam',\n",
       " 'mirtazapine',\n",
       " 'missing',\n",
       " 'ml',\n",
       " 'mls',\n",
       " 'mogadon',\n",
       " 'monoxide',\n",
       " 'mood',\n",
       " 'mother',\n",
       " 'movement',\n",
       " 'multiple',\n",
       " 'mum',\n",
       " 'n',\n",
       " 'nad',\n",
       " 'naloxone',\n",
       " 'naltrexone',\n",
       " 'naprogesic',\n",
       " 'natal',\n",
       " 'nausea',\n",
       " 'nearby',\n",
       " 'nil',\n",
       " 'nitrazepam',\n",
       " 'noose',\n",
       " 'note',\n",
       " 'novomix',\n",
       " 'novorapid',\n",
       " 'numbness',\n",
       " 'nurofen',\n",
       " 'o/d',\n",
       " 'ocd',\n",
       " 'od',\n",
       " 'olanzapine',\n",
       " 'ongoing',\n",
       " 'onset',\n",
       " 'oral',\n",
       " 'origin',\n",
       " 'ormond',\n",
       " 'orygen',\n",
       " 'osteo',\n",
       " 'outreach',\n",
       " 'overdose',\n",
       " 'overdosed',\n",
       " 'overdoses',\n",
       " 'overwhelmed',\n",
       " 'oxazepam',\n",
       " 'oxycodone',\n",
       " 'oxycontin',\n",
       " 'oxynorm',\n",
       " 'ozpan',\n",
       " 'pacer',\n",
       " 'pack',\n",
       " 'packet',\n",
       " 'packets',\n",
       " 'pain',\n",
       " 'painfree',\n",
       " 'painful',\n",
       " 'painter',\n",
       " 'palpation',\n",
       " 'palpitations',\n",
       " 'panadeine',\n",
       " 'panadol',\n",
       " 'panamax',\n",
       " 'paracetamol',\n",
       " 'parents',\n",
       " 'paroxetine',\n",
       " 'partner',\n",
       " 'pd',\n",
       " 'pellets',\n",
       " 'periactin',\n",
       " 'personality',\n",
       " 'pharmacy',\n",
       " 'phenergan',\n",
       " 'phosphate',\n",
       " 'pills',\n",
       " 'plan',\n",
       " 'plans',\n",
       " 'playing',\n",
       " 'plus',\n",
       " 'poison',\n",
       " 'polar',\n",
       " 'police',\n",
       " 'polish',\n",
       " 'poly',\n",
       " 'polypharm',\n",
       " 'polypharmacy',\n",
       " 'possibly',\n",
       " 'ppm',\n",
       " 'prazosin',\n",
       " 'pregabalin',\n",
       " 'previous',\n",
       " 'pristine',\n",
       " 'pristiq',\n",
       " 'productive',\n",
       " 'promethazine',\n",
       " 'propranolol',\n",
       " 'prozac',\n",
       " 'ps',\n",
       " 'psych',\n",
       " 'psyche',\n",
       " 'psychiatrist',\n",
       " 'psychologist',\n",
       " 'psychosis',\n",
       " 'ptsd',\n",
       " 'pupils',\n",
       " 'qt',\n",
       " 'quality',\n",
       " 'quantities',\n",
       " 'quantity',\n",
       " 'questions',\n",
       " 'quetiapine',\n",
       " 'r',\n",
       " 'radiating',\n",
       " 'ramsay',\n",
       " 'rang',\n",
       " 'rash',\n",
       " 'rat',\n",
       " 'razor',\n",
       " 'referred',\n",
       " 'refusing',\n",
       " 'relationship',\n",
       " 'relax',\n",
       " 'release',\n",
       " 'relief',\n",
       " 'reluctant',\n",
       " 'remorseful',\n",
       " 'renal',\n",
       " 'resolved',\n",
       " 'respiradone',\n",
       " 'restavit',\n",
       " 'restrained',\n",
       " 'right',\n",
       " 'risperidone',\n",
       " 'ritalin',\n",
       " 'rivotril',\n",
       " 'rom',\n",
       " 'rope',\n",
       " 'rousable',\n",
       " 'rouse',\n",
       " 'sack',\n",
       " 'sad',\n",
       " 'scalpel',\n",
       " 'scars',\n",
       " 'schizo',\n",
       " 'schizoaffective',\n",
       " 'schizophrenia',\n",
       " 'scissors',\n",
       " 'scotch',\n",
       " 'scratches',\n",
       " 'searched',\n",
       " 'sect',\n",
       " 'section',\n",
       " 'section351',\n",
       " 'sectioned',\n",
       " 'seeker',\n",
       " 'self',\n",
       " 'self-harm',\n",
       " 'self-inflicted',\n",
       " 'sensation',\n",
       " 'sentences',\n",
       " 'separation',\n",
       " 'sequel',\n",
       " 'serepax',\n",
       " 'seroquel',\n",
       " 'sertraline',\n",
       " 'severe',\n",
       " 'sewing',\n",
       " 'shackled',\n",
       " 'sharp',\n",
       " 'shit',\n",
       " 'shoulder',\n",
       " 'si',\n",
       " 'sided',\n",
       " 'sister',\n",
       " 'sisters',\n",
       " 'situational',\n",
       " 'slash',\n",
       " 'slashed',\n",
       " 'sleep',\n",
       " 'sleeping',\n",
       " 'sleepy',\n",
       " 'slit',\n",
       " 'snapped',\n",
       " 'sob',\n",
       " 'social',\n",
       " 'sodium',\n",
       " 'sore',\n",
       " 'speaking',\n",
       " 'spirits',\n",
       " 'ssri',\n",
       " 'stab',\n",
       " 'stabbed',\n",
       " 'standard',\n",
       " 'stanley',\n",
       " 'stated',\n",
       " 'states',\n",
       " 'stating',\n",
       " 'stilnox',\n",
       " 'stole',\n",
       " 'stresses',\n",
       " 'stressor',\n",
       " 'stressors',\n",
       " 'suboxone',\n",
       " 'substance',\n",
       " 'substances',\n",
       " 'sudafed',\n",
       " 'sudden',\n",
       " 'suicidal',\n",
       " 'suicide',\n",
       " 'superficial',\n",
       " 'supp',\n",
       " 'support',\n",
       " 'supported',\n",
       " 'surgery',\n",
       " 'suturing',\n",
       " 'swallowed',\n",
       " 'swelling',\n",
       " 'swollen',\n",
       " 'symptoms',\n",
       " 'syrup',\n",
       " 'tab',\n",
       " 'tables',\n",
       " 'tablet',\n",
       " 'tablets',\n",
       " 'tabs',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'tearful',\n",
       " 'teary',\n",
       " 'telling',\n",
       " 'temaze',\n",
       " 'temazepam',\n",
       " 'temperature',\n",
       " 'text',\n",
       " 'texted',\n",
       " 'thigh',\n",
       " 'thoughts',\n",
       " 'threatened',\n",
       " 'threatening',\n",
       " 'throat',\n",
       " 'tightness',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'topamax',\n",
       " 'total',\n",
       " 'train',\n",
       " 'tramadol',\n",
       " 'transgender',\n",
       " 'trinitrate',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twitchy',\n",
       " 'unable',\n",
       " 'uncooperative',\n",
       " 'units',\n",
       " 'unknown',\n",
       " 'unwell',\n",
       " 'upset',\n",
       " 'urinary',\n",
       " 'urine',\n",
       " 'use',\n",
       " 'uti',\n",
       " 'v',\n",
       " 'v1',\n",
       " 'valdoxan',\n",
       " 'valium',\n",
       " 'valproate',\n",
       " 'venlafaxine',\n",
       " 'vials',\n",
       " 'view',\n",
       " 'violence',\n",
       " 'vision',\n",
       " 'vodka',\n",
       " 'voice',\n",
       " 'voices',\n",
       " 'voicing',\n",
       " 'voluntary',\n",
       " 'vomited',\n",
       " 'vomiting',\n",
       " 'wake',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wanting',\n",
       " 'wants',\n",
       " 'weakness',\n",
       " 'weapons',\n",
       " 'webster',\n",
       " 'weed',\n",
       " 'welfare',\n",
       " 'whisky',\n",
       " 'willing',\n",
       " 'wine',\n",
       " 'wishing',\n",
       " 'withdrawn',\n",
       " 'worker',\n",
       " 'worse',\n",
       " 'worsening',\n",
       " 'worth',\n",
       " 'wound',\n",
       " 'wounds',\n",
       " 'wrist',\n",
       " 'wrists',\n",
       " 'written',\n",
       " 'wrote',\n",
       " 'x',\n",
       " 'xanax',\n",
       " 'youth',\n",
       " 'zoloft',\n",
       " 'zopiclone',\n",
       " 'zyprexa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_rmh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf36afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abdo',\n",
       " 'abscond',\n",
       " 'absconded',\n",
       " 'abuse',\n",
       " 'abusive',\n",
       " 'accom',\n",
       " 'accommodation',\n",
       " 'achy',\n",
       " 'active',\n",
       " 'addict',\n",
       " 'adipose',\n",
       " 'admits',\n",
       " 'afebrile',\n",
       " 'affect',\n",
       " 'aggressive',\n",
       " 'agitated',\n",
       " 'alcohol',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'alprazolam',\n",
       " 'altercation',\n",
       " 'ambulance',\n",
       " 'analgesia',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'ankle',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'antidepressants',\n",
       " 'anxiety',\n",
       " 'anymore',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'area',\n",
       " 'argument',\n",
       " 'arms',\n",
       " 'arrival',\n",
       " 'assoc',\n",
       " 'associated',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempts',\n",
       " 'attendance',\n",
       " 'av',\n",
       " 'avanza',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'awake',\n",
       " 'baclofen',\n",
       " 'bandaged',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'belong',\n",
       " 'berry',\n",
       " 'bib',\n",
       " 'biba',\n",
       " 'bipolar',\n",
       " 'blade',\n",
       " 'bleach',\n",
       " 'blunted',\n",
       " 'borderline',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bourbon',\n",
       " 'bowel',\n",
       " 'bowels',\n",
       " 'boyfriend',\n",
       " 'bpd',\n",
       " 'breakdown',\n",
       " 'broke',\n",
       " 'brought',\n",
       " 'bullied',\n",
       " 'bullying',\n",
       " 'c/o',\n",
       " 'called',\n",
       " 'calm',\n",
       " 'calmer',\n",
       " 'campral',\n",
       " 'cannabis',\n",
       " 'cans',\n",
       " 'capsicum',\n",
       " 'carer',\n",
       " 'case',\n",
       " 'catapres',\n",
       " 'caused',\n",
       " 'central',\n",
       " 'chest',\n",
       " 'children',\n",
       " 'citalopram',\n",
       " 'claims',\n",
       " 'clear',\n",
       " 'clonazepam',\n",
       " 'cm',\n",
       " 'commands',\n",
       " 'commit',\n",
       " 'committed',\n",
       " 'communicate',\n",
       " 'community',\n",
       " 'compliant',\n",
       " 'consumed',\n",
       " 'consumption',\n",
       " 'contact',\n",
       " 'contacted',\n",
       " 'conversation',\n",
       " 'conversing',\n",
       " 'cooperative',\n",
       " 'cops',\n",
       " 'cough',\n",
       " 'councillor',\n",
       " 'counselling',\n",
       " 'counsellor',\n",
       " 'court',\n",
       " 'cpr',\n",
       " 'crcu',\n",
       " 'crisis',\n",
       " 'cuffed',\n",
       " 'cuffs',\n",
       " 'custody',\n",
       " 'cut',\n",
       " 'cuts',\n",
       " 'cutting',\n",
       " 'cymbalta',\n",
       " 'dad',\n",
       " 'decreased',\n",
       " 'deeper',\n",
       " 'deflation',\n",
       " 'deformity',\n",
       " 'deliberate',\n",
       " 'deliberately',\n",
       " 'demeanour',\n",
       " 'denim',\n",
       " 'depressants',\n",
       " 'depressed',\n",
       " 'depression',\n",
       " 'desire',\n",
       " 'developed',\n",
       " 'dexamphetamine',\n",
       " 'dhs',\n",
       " 'dial',\n",
       " 'diarrhoea',\n",
       " 'diazepam',\n",
       " 'die',\n",
       " 'disagreement',\n",
       " 'disclose',\n",
       " 'discomfort',\n",
       " 'discuss',\n",
       " 'disorder',\n",
       " 'dispute',\n",
       " 'divulge',\n",
       " 'dizziness',\n",
       " 'domestic',\n",
       " 'dose',\n",
       " 'doxylamine',\n",
       " 'drank',\n",
       " 'drinking',\n",
       " 'drowsiness',\n",
       " 'drowsy',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'duloxetine',\n",
       " 'easily',\n",
       " 'effect',\n",
       " 'elaborate',\n",
       " 'emotional',\n",
       " 'end',\n",
       " 'endep',\n",
       " 'engage',\n",
       " 'engaging',\n",
       " 'epilim',\n",
       " 'escitalopram',\n",
       " 'escort',\n",
       " 'etoh',\n",
       " 'ex',\n",
       " 'expressed',\n",
       " 'expressing',\n",
       " 'eyes',\n",
       " 'facebook',\n",
       " 'fall',\n",
       " 'family',\n",
       " 'father',\n",
       " 'fell',\n",
       " 'fiance',\n",
       " 'fight',\n",
       " 'filing',\n",
       " 'finger',\n",
       " 'flank',\n",
       " 'flat',\n",
       " 'flexor',\n",
       " 'fluoxetine',\n",
       " 'flynn',\n",
       " 'following',\n",
       " 'foot',\n",
       " 'forearm',\n",
       " 'forearms',\n",
       " 'fracture',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'frustration',\n",
       " 'gcs',\n",
       " 'girlfriend',\n",
       " 'girls',\n",
       " 'given',\n",
       " 'glyceryl',\n",
       " 'goodbye',\n",
       " 'gp',\n",
       " 'grams',\n",
       " 'grandmother',\n",
       " 'grandparents',\n",
       " 'guarantee',\n",
       " 'guarantees',\n",
       " 'halm',\n",
       " 'handcuffed',\n",
       " 'handcuffs',\n",
       " 'handful',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'happy',\n",
       " 'harm',\n",
       " 'harmed',\n",
       " 'harming',\n",
       " 'harms',\n",
       " 'headache',\n",
       " 'health',\n",
       " 'help',\n",
       " 'herbal',\n",
       " 'heroin',\n",
       " 'hot',\n",
       " 'house',\n",
       " 'housemate',\n",
       " 'husband',\n",
       " 'ideation',\n",
       " 'ideations',\n",
       " 'imovane',\n",
       " 'increased',\n",
       " 'inflicted',\n",
       " 'information',\n",
       " 'informed',\n",
       " 'ingested',\n",
       " 'ingesting',\n",
       " 'ingestion',\n",
       " 'injected',\n",
       " 'injury',\n",
       " 'intended',\n",
       " 'intending',\n",
       " 'intent',\n",
       " 'intention',\n",
       " 'intentional',\n",
       " 'intentionally',\n",
       " 'interacting',\n",
       " 'interaction',\n",
       " 'interactive',\n",
       " 'intermittent',\n",
       " 'interval',\n",
       " 'intoxicated',\n",
       " 'intubate',\n",
       " 'issues',\n",
       " 'joking',\n",
       " 'jovial',\n",
       " 'kids',\n",
       " 'kill',\n",
       " 'killing',\n",
       " 'kitchen',\n",
       " 'knee',\n",
       " 'knife',\n",
       " 'laceration',\n",
       " 'lacerations',\n",
       " 'lamotrigine',\n",
       " 'largactil',\n",
       " 'law',\n",
       " 'leave',\n",
       " 'leg',\n",
       " 'leggings',\n",
       " 'length',\n",
       " 'letters',\n",
       " 'lexapro',\n",
       " 'life',\n",
       " 'lifeline',\n",
       " 'ligature',\n",
       " 'lithium',\n",
       " 'live',\n",
       " 'loc',\n",
       " 'looking',\n",
       " 'lorazepam',\n",
       " 'lovan',\n",
       " 'lower',\n",
       " 'lyrica',\n",
       " 'maintaining',\n",
       " 'making',\n",
       " 'managed',\n",
       " 'manager',\n",
       " 'mapa',\n",
       " 'mappa',\n",
       " 'marijuana',\n",
       " 'marks',\n",
       " 'mcg',\n",
       " 'medication',\n",
       " 'medications',\n",
       " 'meds',\n",
       " 'melatonin',\n",
       " 'memories',\n",
       " 'mental',\n",
       " 'mersyndol',\n",
       " 'methylated',\n",
       " 'mg',\n",
       " 'mgs',\n",
       " 'mh',\n",
       " 'midazolam',\n",
       " 'mirtazapine',\n",
       " 'missing',\n",
       " 'mood',\n",
       " 'mother',\n",
       " 'movement',\n",
       " 'multiple',\n",
       " 'mum',\n",
       " 'mums',\n",
       " 'naloxone',\n",
       " 'nausea',\n",
       " 'nil',\n",
       " 'note',\n",
       " 'notified',\n",
       " 'o/d',\n",
       " 'obeys',\n",
       " 'obs',\n",
       " 'obvious',\n",
       " 'ocd',\n",
       " 'od',\n",
       " 'officers',\n",
       " 'olanzapine',\n",
       " 'onset',\n",
       " 'openly',\n",
       " 'oral',\n",
       " 'overdose',\n",
       " 'overdosed',\n",
       " 'overdoses',\n",
       " 'overdosing',\n",
       " 'oxazepam',\n",
       " 'oxybutynin',\n",
       " 'oxycontin',\n",
       " 'packet',\n",
       " 'packets',\n",
       " 'pain',\n",
       " 'painful',\n",
       " 'palpation',\n",
       " 'paracetamol',\n",
       " 'parents',\n",
       " 'paroxetine',\n",
       " 'partner',\n",
       " 'partners',\n",
       " 'pat',\n",
       " 'personality',\n",
       " 'pharmacy',\n",
       " 'phenergan',\n",
       " 'phone',\n",
       " 'phoned',\n",
       " 'pills',\n",
       " 'plan',\n",
       " 'plans',\n",
       " 'pleasant',\n",
       " 'poisons',\n",
       " 'police',\n",
       " 'poly',\n",
       " 'polypharm',\n",
       " 'polypharmacy',\n",
       " 'post',\n",
       " 'posted',\n",
       " 'presents',\n",
       " 'pristine',\n",
       " 'pristiq',\n",
       " 'prompting',\n",
       " 'psych',\n",
       " 'psychiatric',\n",
       " 'psychiatrist',\n",
       " 'psychologist',\n",
       " 'ptsd',\n",
       " 'purpose',\n",
       " 'pv',\n",
       " 'q10',\n",
       " 'qt',\n",
       " 'quantities',\n",
       " 'quantity',\n",
       " 'questions',\n",
       " 'quetiapine',\n",
       " 'quiet',\n",
       " 'radiating',\n",
       " 'rang',\n",
       " 'rape',\n",
       " 'rash',\n",
       " 'razor',\n",
       " 'razorblades',\n",
       " 'reasons',\n",
       " 'redness',\n",
       " 'relationship',\n",
       " 'release',\n",
       " 'relief',\n",
       " 'relieve',\n",
       " 'remorseful',\n",
       " 'reportedly',\n",
       " 'residential',\n",
       " 'respiradone',\n",
       " 'responds',\n",
       " 'responsive',\n",
       " 'restavit',\n",
       " 'restrained',\n",
       " 'restraints',\n",
       " 'reusable',\n",
       " 'rid',\n",
       " 'right',\n",
       " 'risperidone',\n",
       " 'ritalin',\n",
       " 'rope',\n",
       " 'rousable',\n",
       " 'rouse',\n",
       " 'roused',\n",
       " 'rouses',\n",
       " 'rt',\n",
       " 'rub',\n",
       " 'sad',\n",
       " 'safe',\n",
       " 'sandomigran',\n",
       " 'say',\n",
       " 'scars',\n",
       " 'schizophrenia',\n",
       " 'scissors',\n",
       " 'scotch',\n",
       " 'scratches',\n",
       " 'search',\n",
       " 'searched',\n",
       " 'section',\n",
       " 'section351',\n",
       " 'sedated',\n",
       " 'seeking',\n",
       " 'self',\n",
       " 'self-harm',\n",
       " 'self-inflicted',\n",
       " 'sensation',\n",
       " 'sent',\n",
       " 'separation',\n",
       " 'sequel',\n",
       " 'serepax',\n",
       " 'seroquel',\n",
       " 'sertraline',\n",
       " 'services',\n",
       " 'sharp',\n",
       " 'shots',\n",
       " 'shoulder',\n",
       " 'sided',\n",
       " 'silly',\n",
       " 'singlet',\n",
       " 'sister',\n",
       " 'slashed',\n",
       " 'slashing',\n",
       " 'sleep',\n",
       " 'sleeper',\n",
       " 'sleepy',\n",
       " 'slurring',\n",
       " 'smells',\n",
       " 'sob',\n",
       " 'social',\n",
       " 'sodium',\n",
       " 'soft',\n",
       " 'softly',\n",
       " 'sore',\n",
       " 'spirits',\n",
       " 'spoken',\n",
       " 'stab',\n",
       " 'stabbed',\n",
       " 'staff',\n",
       " 'stapled',\n",
       " 'started',\n",
       " 'state',\n",
       " 'stated',\n",
       " 'stating',\n",
       " 'steak',\n",
       " 'stilnox',\n",
       " 'stimuli',\n",
       " 'strangle',\n",
       " 'stress',\n",
       " 'stresses',\n",
       " 'stressor',\n",
       " 'stressors',\n",
       " 'substances',\n",
       " 'sudafed',\n",
       " 'sudden',\n",
       " 'suicidal',\n",
       " 'suicidality',\n",
       " 'suicide',\n",
       " 'superficial',\n",
       " 'supported',\n",
       " 'supportive',\n",
       " 'swallowed',\n",
       " 'swelling',\n",
       " 'swollen',\n",
       " 'symptoms',\n",
       " 'tab',\n",
       " 'tablet',\n",
       " 'tablets',\n",
       " 'tabs',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'talk',\n",
       " 'team',\n",
       " 'teary',\n",
       " 'tells',\n",
       " 'temaze',\n",
       " 'temazepam',\n",
       " 'tender',\n",
       " 'tenderness',\n",
       " 'text',\n",
       " 'texted',\n",
       " 'thighs',\n",
       " 'thoughts',\n",
       " 'threatened',\n",
       " 'threatening',\n",
       " 'thumb',\n",
       " 'tied',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'trigger',\n",
       " 'triggered',\n",
       " 'trinitrate',\n",
       " 'troubles',\n",
       " 'unable',\n",
       " 'units',\n",
       " 'unknown',\n",
       " 'unwell',\n",
       " 'upset',\n",
       " 'urinary',\n",
       " 'urine',\n",
       " 'use',\n",
       " 'valium',\n",
       " 'valproate',\n",
       " 'venlafaxine',\n",
       " 'verbally',\n",
       " 'vodka',\n",
       " 'voice',\n",
       " 'voices',\n",
       " 'voicing',\n",
       " 'voluntarily',\n",
       " 'voluntary',\n",
       " 'vomiting',\n",
       " 'wake',\n",
       " 'wakes',\n",
       " 'wandered',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'wanting',\n",
       " 'wants',\n",
       " 'weapons',\n",
       " 'webster',\n",
       " 'welfare',\n",
       " 'whisky',\n",
       " 'willing',\n",
       " 'wine',\n",
       " 'wish',\n",
       " 'withdrawn',\n",
       " 'worker',\n",
       " 'worse',\n",
       " 'worth',\n",
       " 'worthless',\n",
       " 'wounds',\n",
       " 'wrist',\n",
       " 'wrists',\n",
       " 'written',\n",
       " 'wrote',\n",
       " 'x',\n",
       " 'x-ray',\n",
       " 'xanax',\n",
       " 'yesterday',\n",
       " 'zoloft',\n",
       " 'zopiclone',\n",
       " 'zyprexa']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_lvrh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2a2e82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abilify',\n",
       " 'acid',\n",
       " 'acs',\n",
       " 'addiction',\n",
       " 'adhd',\n",
       " 'advil',\n",
       " 'af',\n",
       " 'ago',\n",
       " 'ami',\n",
       " 'amitriptyline',\n",
       " 'amounts',\n",
       " 'ams',\n",
       " 'ane',\n",
       " 'antidepressant',\n",
       " 'argumentative',\n",
       " 'arterial',\n",
       " 'asylum',\n",
       " 'auditory',\n",
       " 'balcony',\n",
       " 'beech',\n",
       " 'behavioural',\n",
       " 'ben',\n",
       " 'bends',\n",
       " 'benzodiazepine',\n",
       " 'benztropine',\n",
       " 'bibp',\n",
       " 'blades',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'bpad',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'breakup',\n",
       " 'bridge',\n",
       " 'bulimia',\n",
       " 'burning',\n",
       " 'butchers',\n",
       " 'butter',\n",
       " 'ca',\n",
       " 'cade',\n",
       " 'caffeine',\n",
       " 'carbon',\n",
       " 'catt',\n",
       " 'ccf',\n",
       " 'champagne',\n",
       " 'chol',\n",
       " 'clonidine',\n",
       " 'cms',\n",
       " 'cocaine',\n",
       " 'codeine',\n",
       " 'codral',\n",
       " 'communication',\n",
       " 'copd',\n",
       " 'cp',\n",
       " 'crying',\n",
       " 'ct',\n",
       " 'cub',\n",
       " 'cubital',\n",
       " 'cutter',\n",
       " 'death',\n",
       " 'dep',\n",
       " 'depressive',\n",
       " 'difficulty',\n",
       " 'direct',\n",
       " 'distressed',\n",
       " 'dm',\n",
       " 'dosage',\n",
       " 'doses',\n",
       " 'drowning',\n",
       " 'ds',\n",
       " 'dsh',\n",
       " 'ecatt',\n",
       " 'enalapril',\n",
       " 'endone',\n",
       " 'epigastric',\n",
       " 'ett',\n",
       " 'evasive',\n",
       " 'extra',\n",
       " 'face',\n",
       " 'facial',\n",
       " 'febrile',\n",
       " 'fever',\n",
       " 'fevers',\n",
       " 'fluctuating',\n",
       " 'forte',\n",
       " 'forthcoming',\n",
       " 'g',\n",
       " 'gambling',\n",
       " 'gamma',\n",
       " 'generalised',\n",
       " 'glass',\n",
       " 'glasses',\n",
       " 'gm',\n",
       " 'grey',\n",
       " 'gx',\n",
       " 'half',\n",
       " 'hallucinations',\n",
       " 'head',\n",
       " 'headspace',\n",
       " 'headstrike',\n",
       " 'hip',\n",
       " 'hours',\n",
       " 'housemates',\n",
       " 'hs',\n",
       " 'ht',\n",
       " 'htn',\n",
       " 'hurt',\n",
       " 'hydrochloric',\n",
       " 'hydroxybutyric',\n",
       " 'ibuprofen',\n",
       " 'ice',\n",
       " 'idea',\n",
       " 'improvement',\n",
       " 'increasing',\n",
       " 'infection',\n",
       " 'infested',\n",
       " 'inspiration',\n",
       " 'intentions',\n",
       " 'ivdu',\n",
       " 'john',\n",
       " 'jump',\n",
       " 'jumped',\n",
       " 'kalma',\n",
       " 'ken',\n",
       " 'key',\n",
       " 'l',\n",
       " 'lac',\n",
       " 'lamictal',\n",
       " 'left',\n",
       " 'lethargy',\n",
       " 'lighter',\n",
       " 'lmo',\n",
       " 'longer',\n",
       " 'looks',\n",
       " 'magic',\n",
       " 'maintains',\n",
       " 'major',\n",
       " 'mate',\n",
       " 'mechanical',\n",
       " 'medicating',\n",
       " 'message',\n",
       " 'methadone',\n",
       " 'micardis',\n",
       " 'ml',\n",
       " 'mls',\n",
       " 'mogadon',\n",
       " 'monoxide',\n",
       " 'n',\n",
       " 'nad',\n",
       " 'naltrexone',\n",
       " 'naprogesic',\n",
       " 'natal',\n",
       " 'nearby',\n",
       " 'nitrazepam',\n",
       " 'noose',\n",
       " 'novomix',\n",
       " 'novorapid',\n",
       " 'numbness',\n",
       " 'nurofen',\n",
       " 'ongoing',\n",
       " 'origin',\n",
       " 'ormond',\n",
       " 'orygen',\n",
       " 'osteo',\n",
       " 'outreach',\n",
       " 'overwhelmed',\n",
       " 'oxycodone',\n",
       " 'oxynorm',\n",
       " 'ozpan',\n",
       " 'pacer',\n",
       " 'pack',\n",
       " 'painfree',\n",
       " 'painter',\n",
       " 'palpitations',\n",
       " 'panadeine',\n",
       " 'panadol',\n",
       " 'panamax',\n",
       " 'pd',\n",
       " 'pellets',\n",
       " 'periactin',\n",
       " 'phosphate',\n",
       " 'playing',\n",
       " 'plus',\n",
       " 'poison',\n",
       " 'polar',\n",
       " 'polish',\n",
       " 'possibly',\n",
       " 'ppm',\n",
       " 'prazosin',\n",
       " 'pregabalin',\n",
       " 'previous',\n",
       " 'productive',\n",
       " 'promethazine',\n",
       " 'propranolol',\n",
       " 'prozac',\n",
       " 'ps',\n",
       " 'psyche',\n",
       " 'psychosis',\n",
       " 'pupils',\n",
       " 'quality',\n",
       " 'r',\n",
       " 'ramsay',\n",
       " 'rat',\n",
       " 'referred',\n",
       " 'refusing',\n",
       " 'relax',\n",
       " 'reluctant',\n",
       " 'renal',\n",
       " 'resolved',\n",
       " 'rivotril',\n",
       " 'rom',\n",
       " 'sack',\n",
       " 'scalpel',\n",
       " 'schizo',\n",
       " 'schizoaffective',\n",
       " 'sect',\n",
       " 'sectioned',\n",
       " 'seeker',\n",
       " 'sentences',\n",
       " 'severe',\n",
       " 'sewing',\n",
       " 'shackled',\n",
       " 'shit',\n",
       " 'si',\n",
       " 'sisters',\n",
       " 'situational',\n",
       " 'slash',\n",
       " 'sleeping',\n",
       " 'slit',\n",
       " 'snapped',\n",
       " 'speaking',\n",
       " 'ssri',\n",
       " 'standard',\n",
       " 'stanley',\n",
       " 'states',\n",
       " 'stole',\n",
       " 'suboxone',\n",
       " 'substance',\n",
       " 'supp',\n",
       " 'support',\n",
       " 'surgery',\n",
       " 'suturing',\n",
       " 'syrup',\n",
       " 'tables',\n",
       " 'tearful',\n",
       " 'telling',\n",
       " 'temperature',\n",
       " 'thigh',\n",
       " 'throat',\n",
       " 'tightness',\n",
       " 'topamax',\n",
       " 'total',\n",
       " 'train',\n",
       " 'tramadol',\n",
       " 'transgender',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twitchy',\n",
       " 'uncooperative',\n",
       " 'uti',\n",
       " 'v',\n",
       " 'v1',\n",
       " 'valdoxan',\n",
       " 'vials',\n",
       " 'view',\n",
       " 'violence',\n",
       " 'vision',\n",
       " 'vomited',\n",
       " 'weakness',\n",
       " 'weed',\n",
       " 'wishing',\n",
       " 'worsening',\n",
       " 'wound',\n",
       " 'youth'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(selected_features_rmh) - set(selected_features_lvrh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad26adf",
   "metadata": {},
   "source": [
    "___\n",
    "# Patient cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed081d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_filename = \"rmh_2012_2022\" # rmh_2012_2022, lvrh_2012_2022\n",
    "site = \"RMH\"\n",
    "df = pd.read_parquet(data_interim_dir / (data_filename + \"_cleaned.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b07579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of presentations \n",
    "df.year.value_counts().agg(['mean', 'std']).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "df.age.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2cbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex\n",
    "df.sex.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrival method\n",
    "df.arrival_method.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2516cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proportions(df, col, title, legend=True):\n",
    "    tmp = df.groupby('SH')[col].value_counts(normalize=True).reset_index()\n",
    "    tmp.proportion = tmp.proportion*100\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (3, 3)\n",
    "\n",
    "    n_cat = len(df[col].cat.categories)\n",
    "\n",
    "    palette = sns.color_palette('tab10', n_cat)\n",
    "\n",
    "    for i in range(n_cat):\n",
    "        sns.barplot(x='SH', y='proportion', data=tmp[tmp[col].isin(df[col].cat.categories[i:])], \n",
    "                    estimator=sum, errorbar=None, \n",
    "                    label=df[col].cat.categories[i].capitalize(), color=palette[i]);\n",
    "\n",
    "    plt.xticks(ticks=(0,1), labels=('Negative', 'Positive'));\n",
    "    plt.yticks(ticks=(0, 50, 100));\n",
    "    plt.xlabel('Self-harm');\n",
    "    plt.ylabel('Percentage');\n",
    "    if legend:\n",
    "        plt.legend(bbox_to_anchor=(1, 1.035));\n",
    "    else:\n",
    "        plt.legend(None)\n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions(df, 'sex', site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a80772",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proportions(df, 'arrival_method', site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7726ad9",
   "metadata": {},
   "source": [
    "___\n",
    "# Length of triage notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_filename = \"rmh_2012_2022\" # rmh_2012_2022, lvrh_2012_2022\n",
    "site = \"RMH\"\n",
    "df = pd.read_parquet(data_interim_dir / (data_filename + \"_cleaned.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf202321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='year', y='length', \n",
    "            #  hue=df.SH.map({0: 'Negative', 1: 'Positive'}), \n",
    "             data=df, \n",
    "            #  estimator='mean', errorbar='sd', \n",
    "             lw=2, \n",
    "            #  palette={'Negative': sns.color_palette('tab10')[7], \n",
    "            #           'Positive': sns.color_palette('tab10')[3]}\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dedb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_length_over_time(df, title, annotate_dev=True):\n",
    "    \"\"\"Plot character length of triage notes over time\"\"\"\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (df.quarter.nunique() * 12 / 40, 3)\n",
    "\n",
    "    sns.lineplot(x='quarter', y='length', hue=df.SH.map({0: 'Negative', 1: 'Positive'}), data=df, \n",
    "                 estimator='mean', errorbar='sd', \n",
    "                 lw=2, palette={'Negative': sns.color_palette('tab10')[7], \n",
    "                                'Positive': sns.color_palette('tab10')[3]})\n",
    "    \n",
    "    if annotate_dev:\n",
    "        # Horisontal line: dev and test sets\n",
    "        plt.plot([0, 23], [300, 300], marker='s', markevery=True, color=sns.color_palette('tab20c')[-4]);\n",
    "    \n",
    "    # Axes limits, ticks, and labels\n",
    "    plt.ylim([50, 600]);\n",
    "    plt.xticks(rotation=45, \n",
    "               ticks=range(0, df.quarter.nunique(), 2), \n",
    "               labels=[format_quarter(q) for q in df.quarter.cat.categories.astype(str) \n",
    "                       if q.endswith('1') or q.endswith('3')]);\n",
    "    plt.xlabel(\"Arrival date\");\n",
    "    plt.ylabel(\"Character length\");\n",
    "    plt.legend(title='Self-harm');\n",
    "\n",
    "    # Title\n",
    "    plt.title(title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length_over_time(df, site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956488f",
   "metadata": {},
   "source": [
    "___\n",
    "# Proportions of SH and SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b30b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = \"../datasets/\"\n",
    "data_filename = \"lvrh_2012_2022_cleaned\" # rmh_2012_2022_cleaned, lvrh_2012_2022_cleaned\n",
    "site = \"LRH\"\n",
    "df = pd.read_csv(data_path + data_filename + \".csv\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983835e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.SH.value_counts(dropna=False, normalize=True) * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57aeba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.SI.value_counts(dropna=False, normalize=True) * 100).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3403d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_presentations_over_time(df, title, annotate_dev=True, simple_palette=True):\n",
    "    \"\"\"\n",
    "    Plot the number of presentations and SH/SI rates per quarter.\n",
    "    \"\"\"\n",
    "    # Convert quarter to categorical\n",
    "    df.quarter = df.quarter.astype('category')\n",
    "\n",
    "    # Create subplots\n",
    "    plt.rcParams['figure.figsize'] = (df.quarter.nunique() * 12 / 40, 6)\n",
    "    _, ax1 = plt.subplots()\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Barplot: Numper of ED presentations\n",
    "    if simple_palette:\n",
    "        sns.countplot(x='quarter', data=df, \n",
    "                      color=sns.color_palette('tab20c')[-1],\n",
    "                      ax=ax1);\n",
    "    else:\n",
    "        palette = {year: sns.color_palette('tab20c')[-2] for year in range(2012, 2018)}\n",
    "        palette.update({year: sns.color_palette('tab20c')[-1] for year in range(2018, 2022)})\n",
    "        sns.countplot(x='quarter', data=df, \n",
    "                      palette=palette, hue='year', legend=False,\n",
    "                      ax=ax1);\n",
    "    \n",
    "    if annotate_dev:\n",
    "        # Horisontal line: dev and test sets\n",
    "        plt.plot([-0.5, 23.5], [2.2, 2.2], marker='s', markevery=True, color=sns.color_palette('tab20c')[-4]);\n",
    "\n",
    "\n",
    "    # Vertical line: start of covid\n",
    "    plt.axvline(32.5, 0, 1, color=sns.color_palette('tab20c')[-4], ls='--');\n",
    "    \n",
    "    # Axes limits, ticks, and labels\n",
    "    ax1.set_xticks(rotation=45, \n",
    "                   ticks=range(0, df.quarter.nunique(), 2), \n",
    "                   labels=[format_quarter(q) for q in df.quarter.cat.categories.astype(str) \n",
    "                           if q.endswith('1') or q.endswith('3')]);\n",
    "    ax1.set_xlabel(\"Arrival date\");\n",
    "    ax1.set_ylabel(\"# ED presentations\");\n",
    "\n",
    "    # Lineplot: SH rate per quarter\n",
    "    sns.lineplot(df.groupby(df.quarter.cat.codes).apply(lambda x: \n",
    "                                                    x.SH.sum() / x.shape[0] * 100), \n",
    "                                                    color=sns.color_palette(\"tab10\")[3], lw=2, \n",
    "                                                    label=\"Self-harm\", ax=ax2);\n",
    "    # Lineplot: SI rate per quarter\n",
    "    sns.lineplot(df.groupby(df.quarter.cat.codes).apply(lambda x: \n",
    "                                                    x.SI.sum() / x.shape[0] * 100), \n",
    "                                                    color=sns.color_palette(\"tab10\")[9], lw=2, \n",
    "                                                    label=\"Suicidal ideation\", ax=ax2);\n",
    "    # Axes limits, ticks, and labels\n",
    "    ax2.set_ylim([0, 2.8]);\n",
    "    ax2.set_ylabel(\"% cases\");\n",
    "\n",
    "    # Title\n",
    "    plt.title(title);\n",
    "\n",
    "    # Save plot\n",
    "    plt.savefig(\"../results/\" + title + \" presentations and cases per quarter.jpeg\", bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_presentations_over_time(df, site, annotate_dev=False, simple_palette=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b9f55",
   "metadata": {},
   "source": [
    "___\n",
    "# Number of unique tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f4c5b4",
   "metadata": {},
   "source": [
    "## Development data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af50398b",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dev data\n",
    "dev_data_filename = \"rmh_2012_2017_dev\"\n",
    "name = \"Development\"\n",
    "df_dev = pd.read_parquet(data_proc_dir / (dev_data_filename + \"_normalised.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Convert quarter to categorical\n",
    "df_dev.quarter = df_dev.quarter.astype('category')\n",
    "df_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED vocabulary\n",
    "vocab_filename = \"rmh_2012_2017_dev_amt6\"\n",
    "# Load the ED vocabulary\n",
    "vocab = load_vocab(vocab_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27984715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected features\n",
    "with open(models_dir / (dev_data_filename + \"_selected_fts.txt\"), 'r') as f:\n",
    "    selected_features = f.read().split()\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155bfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_counts = count_vocab_tokens_in_data(df_dev.entities, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f142d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../datasets/spelling_correction/negation_terms.txt\", 'r') as f:\n",
    "#     negation_terms = f.read().split()\n",
    "# len(negation_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b09cd",
   "metadata": {},
   "source": [
    "### Temporal changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f339b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dim_over_time(df_dev, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_overlap_over_time(df_dev, vocab, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1dd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dim_reduction_over_time(df_dev, 'preprocessed_triage_note', 'entities', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_selected_fts_over_time(df_dev, selected_features, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divergence_over_time(df_dev, dev_counts, selected_features, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61570462",
   "metadata": {},
   "source": [
    "## Unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5864278",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load unseen data\n",
    "unseen_data_filename = \"rmh_2012_2017_test\" # rmh_2012_2017_test, rmh_2018_2022, lvrh_2012_2022\n",
    "name = \"Test\"\n",
    "df = pd.read_parquet(data_proc_dir / (unseen_data_filename + \"_normalised.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "# Convert quarter to categorical\n",
    "df.quarter = df.quarter.astype('category')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3159283",
   "metadata": {},
   "source": [
    "### Temporal changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49577c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 & 4. How many unique tokens were there \n",
    "# before and after text normalisation?\n",
    "plot_dim_over_time(df, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 & 5. How similar were the notes to the normalised \n",
    "# development data before and after text normalisation?\n",
    "plot_token_overlap_over_time(df, vocab, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. How effective was text normalisation \n",
    "# in dimensionality reduction? \n",
    "plot_dim_reduction_over_time(df, 'preprocessed_triage_note', 'entities', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. How many of the selected features were \n",
    "# present in the normalised notes?\n",
    "plot_selected_fts_over_time(df, selected_features, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5537fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Distribution of selected features\n",
    "plot_divergence_over_time(df, dev_counts, selected_features, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d9d43",
   "metadata": {},
   "source": [
    "___\n",
    "# Overall predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_filename = \"rmh_2012_2017_dev\" # rmh_2012_2017_test rmh_2018_2022, lvrh_2012_2022\n",
    "title = \"Development\"\n",
    "df = pd.read_parquet(data_pred_dir / (data_filename + \"_predicted.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f274de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_predicted_proba(df, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27aa44e",
   "metadata": {},
   "source": [
    "___\n",
    "# Predcitions over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_filename = \"rmh_2012_2017_dev\" # rmh_2012_2017_test rmh_2018_2022, lvrh_2012_2022\n",
    "title = \"Development\"\n",
    "df = pd.read_parquet(data_pred_dir / (data_filename + \"_predicted.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# Remove data from 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores_over_time(df, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762bbab",
   "metadata": {},
   "source": [
    "# Char length distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_len = 124\n",
    "max_len = 277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb29d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = ((df1.length >= min_len) & (df1.length <= max_len)). sum()\n",
    "n_notes, (n_notes / df1.shape[0] * 100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_notes = ((df2.length >= min_len) & (df2.length <= max_len)). sum()\n",
    "n_notes, (n_notes / df2.shape[0] * 100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c683524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='length', data=df1[(df1.length >= min_len) & (df1.length <= max_len)].sample(10000), binwidth=10);\n",
    "sns.histplot(x='length', data=df2[(df2.length >= min_len) & (df2.length <= max_len)].sample(10000), binwidth=10);\n",
    "plt.xlim([0,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba16df",
   "metadata": {},
   "source": [
    "# Language of triage notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED vocabulary\n",
    "vocab_filename = \"lvrh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Dictionary of misspellings\n",
    "spell_filename = \"rmh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Classifier and threshold\n",
    "model_filename = \"calibrated_lgbm_rmh_2012_2017_dev_amt5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ED vocabulary\n",
    "vocab = load_vocab(vocab_filename)\n",
    "\n",
    "# Load ED word frequency list\n",
    "# word_list = load_word_list(vocab_filename)\n",
    "\n",
    "# Load the dictionary of corrected misspellings\n",
    "# misspelled_dict = load_misspelled_dict(vocab_filename)\n",
    "\n",
    "# Load a pre-trained model and threshold\n",
    "# model, thresh = load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_note_length(df):\n",
    "    print(\"Across the dataset, the average note length is %d (+/- %d)\" % (df.length.mean(), df.length.std()))\n",
    "    print(\"For notes negative for SH, the average note length is %d (+/- %d)\" % (df[df.SH==0].length.mean(), df[df.SH==0].length.std()))\n",
    "    print(\"For notes positive for SH, the average note length is %d (+/- %d)\" % (df[df.SH==1].length.mean(), df[df.SH==1].length.std()))\n",
    "\n",
    "    sns.kdeplot(x='length', data=df, hue='SH', fill=True, common_norm=False);\n",
    "\n",
    "# def check_unknown_words(notes, vocab):\n",
    "#     # Find and count OOV words\n",
    "#     unknown_tokens = find_unknown_tokens(notes, vocab)\n",
    "#     # Top 1% OOV words by frequency\n",
    "#     q = np.quantile(list(unknown_tokens.values()), q=0.99)\n",
    "#     print(\"Top 1% OOV words by frequency:\", q)\n",
    "#     print(\"There are %d such words.\" % sum([v >= q for v in unknown_tokens.values()]))\n",
    "#     print([k for k,v in unknown_tokens.items() if v >= q])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecfe0c2",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset used for analysis\n",
    "unseen_data_filename = \"lvrh_2012_2022\" # \"rmh_2012_2017_dev_amt5\" | \"rmh_2012_2017_test\" | \"rmh_2018_2022\" | \"lvrh_2012_2022\"\n",
    "\n",
    "# Load data for analysis\n",
    "df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_normalised.csv\", \n",
    "                 converters={'triage_note': str, \n",
    "                             'preprocessed_triage_note': str, \n",
    "                             'tokenized_triage_note': str, \n",
    "                             'corrected_triage_note': str, \n",
    "                             'normalised_triage_note': str,\n",
    "                             'entities': str})\n",
    "\n",
    "df = df[df.year < 2018].copy()\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f409eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_tokens = count_tokens(df.entities, valid_tokens_only=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = count_tokens(df.entities, valid_tokens_only=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_tokens = count_tokens(df.entities, valid_tokens_only=True, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([t in dev_tokens for t in test_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([t in dev_tokens for t in ext_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52012e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "32107/75235*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(df.tokenized_triage_note, valid_tokens_only=True, tokens_in_vocab=True, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(df.corrected_triage_note, valid_tokens_only=True, tokens_in_vocab=True, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_note_length(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42377b",
   "metadata": {},
   "source": [
    "### Text normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4408e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd942517",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counts = count_tokens(df.triage_note, valid_tokens_only=True, return_dict=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff04f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proba ~ freq\n",
    "token_counts = count_tokens(df.triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "\n",
    "samples = np.random.choice(a=np.array(list(token_counts.keys())), \n",
    "                          size=(n, m), \n",
    "                          p=np.array(list(token_counts.values())) / sum(token_counts.values())\n",
    "                          )\n",
    "\n",
    "# # Uniform distribution\n",
    "# tokens = []\n",
    "# df.triage_note.apply(lambda x: [tokens.append(token) for token in x.split() if is_valid_token(token)])\n",
    "\n",
    "# samples = np.random.choice(tokens, size=(n, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ea126",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_unique = [np.unique(s).shape for s in samples]\n",
    "print(\"# unique in raw notes: %d (+/- %d)\" % (np.mean(raw_unique), np.std(raw_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2def384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Proba ~ freq\n",
    "# token_counts = count_tokens(df.tokenized_triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "\n",
    "# samples = np.random.choice(a=np.array(list(token_counts.keys())), \n",
    "#                           size=(n, m), \n",
    "#                           p=np.array(list(token_counts.values())) / sum(token_counts.values()))\n",
    "\n",
    "# Uniform distribution\n",
    "tokens = []\n",
    "df.tokenized_triage_note.apply(lambda x: [tokens.append(token) for token in x.split() if is_valid_token(token)])\n",
    "\n",
    "samples = np.random.choice(tokens, size=(n, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_unique = [np.unique(s).shape for s in samples]\n",
    "print(\"# unique in tokenised notes: %d (+/- %d)\" % (np.mean(tok_unique), np.std(tok_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fe9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_known = [len(vocab.intersection(s)) for s in samples]\n",
    "print(\"# known words in tokenised notes: %d (+/- %d)\" % (np.mean(tok_known), np.std(tok_known)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_missp = [len(set(misspelled_dict.keys()).intersection(s)) for s in samples]\n",
    "print(\"# misspellings in tokenised notes: %d (+/- %d)\" % (np.mean(tok_missp), np.std(tok_missp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2930fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Proba ~ freq\n",
    "# token_counts = count_tokens(df.corrected_triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "\n",
    "# samples = np.random.choice(a=np.array(list(token_counts.keys())), \n",
    "#                           size=(n, m), \n",
    "#                           p=np.array(list(token_counts.values())) / sum(token_counts.values()))\n",
    "\n",
    "# Uniform distribution\n",
    "tokens = []\n",
    "df.corrected_triage_note.apply(lambda x: [tokens.append(token) for token in x.split() if is_valid_token(token)])\n",
    "\n",
    "samples = np.random.choice(tokens, size=(n, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5540fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_unique = [np.unique(s).shape for s in samples]\n",
    "print(\"# unique in corrected notes: %d (+/- %d)\" % (np.mean(corr_unique), np.std(corr_unique)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([t not in vocab for t in np.unique(samples[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fa898",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([t in vocab for t in np.unique(samples[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c5fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([t not in samples[0] for t in vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc918ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab.difference(samples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(samples[0]).difference(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c45e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.in1d(samples[0], vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_language_stats(df):\n",
    "    stats = {\n",
    "        'raw_unique': [], \n",
    "        'tok_unique': [],\n",
    "        'tok_reduction': [],\n",
    "        'tok_known': [],\n",
    "        'tok_missp': [],\n",
    "        'tok_oov': [],\n",
    "        'cor_unique': [],\n",
    "        'cor_reduction': [],\n",
    "        'norm_unique': [],\n",
    "        'norm_reduction': [],\n",
    "    }\n",
    "    for i in range(100):\n",
    "        tmp = df[(df.length >= min_len) & (df.length <= max_len)].sample(10000).copy()\n",
    "        # Raw notes\n",
    "        token_counts = count_tokens(tmp.triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "        # unique tokens\n",
    "        raw_unique = len(token_counts.keys())\n",
    "        stats['raw_unique'].append(raw_unique)\n",
    "    \n",
    "        # Tokenised notes\n",
    "        token_counts = count_tokens(tmp.tokenized_triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "        # unique tokens\n",
    "        tok_unique = len(token_counts.keys())\n",
    "        stats['tok_unique'].append(tok_unique)\n",
    "        # reduction\n",
    "        stats['tok_reduction'].append(100 - tok_unique / raw_unique * 100)\n",
    "        # known to vocab\n",
    "        unknown_tokens = [k for k in token_counts.keys() if k not in vocab]\n",
    "        stats['tok_known'].append(tok_unique - len(unknown_tokens))\n",
    "        # misspelled and OOV\n",
    "        oov, missp = np.bincount([k in misspelled_dict for k in unknown_tokens])\n",
    "        stats['tok_missp'].append(missp)\n",
    "        stats['tok_oov'].append(oov)\n",
    "        \n",
    "\n",
    "        # Corrected notes\n",
    "        token_counts = count_tokens(tmp.corrected_triage_note, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "        # unique tokens\n",
    "        cor_unique = len(token_counts.keys())\n",
    "        stats['cor_unique'].append(cor_unique)\n",
    "        # reduction\n",
    "        stats['cor_reduction'].append(100 - cor_unique / tok_unique * 100)\n",
    "\n",
    "        # Normalised notes\n",
    "        token_counts = count_tokens(tmp.entities, valid_tokens_only=True, return_dict=True, verbose=False)\n",
    "        # unique tokens\n",
    "        norm_unique = len(token_counts.keys())\n",
    "        stats['norm_unique'].append(norm_unique)\n",
    "        # reduction\n",
    "        stats['norm_reduction'].append(100 - norm_unique / cor_unique * 100)\n",
    "\n",
    "    print(\"Raw notes\")\n",
    "    print(\"# unique in raw notes: %d (+/- %d)\" % (np.mean(stats['raw_unique']), np.std(stats['raw_unique'])))\n",
    "    print()\n",
    "    print(\"Pre-processing & tokenisation\")\n",
    "    print(\"# unique in tokenised notes: %d (+/- %d)\" % (np.mean(stats['tok_unique']), np.std(stats['tok_unique'])))\n",
    "    print(\"pre-processing & tokenisation reduce dimensionality by %d%% (+/- %d)\" % (np.mean(stats['tok_reduction']), np.std(stats['tok_reduction'])))\n",
    "    print(\"# known words in tokenised notes: %d (+/- %d)\" % (np.mean(stats['tok_known']), np.std(stats['tok_known'])))\n",
    "    print(\"# misspellings in tokenised notes: %d (+/- %d)\" % (np.mean(stats['tok_missp']), np.std(stats['tok_missp'])))\n",
    "    print(\"# OOV words in tokenised notes: %d (+/- %d)\" % (np.mean(stats['tok_oov']), np.std(stats['tok_oov'])))\n",
    "    print()\n",
    "    print(\"Spelling correction\")\n",
    "    print(\"# unique in corrected notes: %d (+/- %d)\" % (np.mean(stats['cor_unique']), np.std(stats['cor_unique'])))\n",
    "    print(\"spelling correction reduces dimensionality by %d%% (+/- %d)\" % (np.mean(stats['cor_reduction']), np.std(stats['cor_reduction'])))\n",
    "    print()\n",
    "    print(\"Final\")\n",
    "    print(\"# unique in corrected notes: %d (+/- %d)\" % (np.mean(stats['norm_unique']), np.std(stats['norm_unique'])))\n",
    "    print(\"Normalisation reduces dimensionality by %d%% (+/- %d)\" % (np.mean(stats['norm_reduction']), np.std(stats['norm_reduction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b5e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_language_stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a997a2",
   "metadata": {},
   "source": [
    "**Token counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tokens(df.triage_note, valid_tokens_only=True)\n",
    "count_tokens(df.preprocessed_triage_note, valid_tokens_only=True)\n",
    "count_tokens(df.tokenized_triage_note, valid_tokens_only=True)\n",
    "count_tokens(df.corrected_triage_note, valid_tokens_only=True)\n",
    "count_tokens(df.normalised_triage_note, valid_tokens_only=True)\n",
    "count_tokens(df.entities, valid_tokens_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a4526",
   "metadata": {},
   "source": [
    "**Raw notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique words and lexical diversity\n",
    "get_language_stats(df.triage_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f4265",
   "metadata": {},
   "source": [
    "**Before spelling correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_language_stats(df.tokenized_triage_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ebcdae",
   "metadata": {},
   "source": [
    "**After spelling correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12835732",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_language_stats(df.corrected_triage_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14adff3",
   "metadata": {},
   "source": [
    "### Uncorrected words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6422e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unknown_words(df.normalised_triage_note, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unknown_tokens = find_correct_spelling(unknown_tokens, misspelled_dict=misspelled_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unknown_tokens = find_correct_spelling(unknown_tokens, \n",
    "                                       misspelled_dict=misspelled_dict, \n",
    "                                       word_list=word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75968924",
   "metadata": {},
   "source": [
    "### Corrected misspellings and  OOV tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51609f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled, oov = split_misspelled_oov(unknown_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f44078",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(misspelled.items(),  key=lambda item: item[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(oov.items(),  key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ded716",
   "metadata": {},
   "outputs": [],
   "source": [
    "misspelled_dict = dict(misspelled_dict, **misspelled)\n",
    "len(misspelled_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630194f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../datasets/spelling_correction/\" + unseen_data_filename + \"_misspelled_dict.pickle\", 'wb') as f:\n",
    "    pickle.dump(misspelled_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66814171",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k,v in misspelled_dict.items() if v==None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f34d1b",
   "metadata": {},
   "source": [
    "# Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset used for analysis\n",
    "unseen_data_filename = \"lvrh_2012_2022\" # \"rmh_2012_2017_dev_amt5\" | \"rmh_2012_2017_test\" | \"rmh_2018_2022\" | \"lvrh_2012_2022\"\n",
    "\n",
    "# Load data for analysis\n",
    "df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_predicted.csv\", \n",
    "                 converters={'triage_note': str, \n",
    "                             'preprocessed_triage_note': str, \n",
    "                             'tokenized_triage_note': str, \n",
    "                             'corrected_triage_note': str, \n",
    "                             'normalised_triage_note': str,\n",
    "                             'entities': str})\n",
    "\n",
    "# Remove 2022\n",
    "df = df[df.year < 2022].copy()\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7139d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification(df.SH, df.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b85fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = []\n",
    "# n = [100, 250, 500, 750, 1000, 1500, 2000, 3000, 5000, 7500, 10000, 15000, 20000, 25000, 30000, 40000, 50000, 100000]\n",
    "n = range(100, 300000, 250)\n",
    "for i in n:\n",
    "    # tmp = df[['SH', 'probability']].sample(i).copy()\n",
    "    tmp = df[['SH', 'probability']].iloc[:i].copy()\n",
    "    thresh.append(select_threshold(tmp.SH, tmp.probability, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2be3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampled\n",
    "sns.lineplot(x=n, y=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consequetive\n",
    "sns.lineplot(x=n, y=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classification(df.SH, threshold_proba(df.probability, thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b32613",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34230865",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/selected_fts_\" + dev_data_filename + \"_amt5.txt\", 'r') as f:\n",
    "    selected_features = f.read().split()\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ee17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/selected_fts_\" + dev_data_filename + \"2.txt\", 'r') as f:\n",
    "    selected_features2 = f.read().split()\n",
    "len(selected_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_v1 = [ft for ft in selected_features if not ft in selected_features2] #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fts_v2 = [ft for ft in selected_features2 if not ft in selected_features] #27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_stopwords()\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ft for ft in fts_v2 if ft in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6757b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ED vocabulary\n",
    "vocab_filename = \"rmh_2012_2017_dev_amt5\"\n",
    "\n",
    "# Selected features\n",
    "vectorizer_filename = \"rmh_2012_2017_dev_amt5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ED vocabulary\n",
    "vocab = load_vocab(vocab_filename)\n",
    "\n",
    "# Load the list of selected features\n",
    "vectorizer = load_vectorizer(vectorizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_fts = frozenset(vectorizer.df_features.feature.tolist())\n",
    "len(selected_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset used for analysis\n",
    "unseen_data_filename = \"lvrh_2012_2022\" # \"rmh_2012_2017_dev_amt5\" | \"rmh_2012_2017_test\" | \"rmh_2018_2022\" | \"lvrh_2012_2022\"\n",
    "\n",
    "# Load data for analysis\n",
    "df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_normalised.csv\", \n",
    "                 converters={'triage_note': str, \n",
    "                             'preprocessed_triage_note': str, \n",
    "                             'tokenized_triage_note': str, \n",
    "                             'corrected_triage_note': str, \n",
    "                             'normalised_triage_note': str,\n",
    "                             'entities': str})\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5cbe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = count_tokens(df.entities, return_dict=True)\n",
    "sum([ft in tokens for ft in selected_fts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(df.entities, df.SH)\n",
    "vectorizer.df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2635732",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.df_features[~vectorizer.df_features.feature.isin(selected_fts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8808b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='probability', data=df, stat='probability', bins=25);\n",
    "plt.ylim([0,0.005])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a4bca",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a907145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    # Load data for analysis\n",
    "    df = pd.read_csv(\"../datasets/\" + filename + \"_predicted.csv\")\n",
    "\n",
    "    # Convert to datetime and extract year and quarter\n",
    "    df.arrival_date = pd.to_datetime(df.arrival_date)\n",
    "    df['year'] = df.arrival_date.dt.year\n",
    "    df['quarter'] = df.arrival_date.dt.to_period('Q')\n",
    "\n",
    "    # Remove 2022\n",
    "    df = df[df.year < 2022].copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4757240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset used for analysis\n",
    "unseen_data_filename = \"rmh_2018_2022\"\n",
    "df1 = load_dataset(unseen_data_filename)\n",
    "df1['hospital'] = 'RMH'\n",
    "\n",
    "unseen_data_filename = \"lvrh_2012_2022\"\n",
    "df2 = load_dataset(unseen_data_filename)\n",
    "df2['hospital'] = 'LRH'\n",
    "\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0dd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot curves\n",
    "# plot_curves(df.SH, df.probability, filename=unseen_data_filename)\n",
    "# # Evaluate classification on the whole dataset\n",
    "# evaluate_classification(df.SH, df.prediction, filename=unseen_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "df.quarter = df.quarter.astype('category')\n",
    "xlim = df.quarter.cat.codes.max() + 1\n",
    "\n",
    "sns.lineplot(x=range(0, xlim), y=0.85, ls='--', \n",
    "             color=sns.color_palette('Paired')[0], label=\"Development set\")\n",
    "sns.lineplot(x=range(0, xlim), y=0.86, ls='--', \n",
    "             color=sns.color_palette('Paired')[2], label=\"Test set\")\n",
    "sns.lineplot(x=range(0, xlim), y=0.83, ls='--', \n",
    "             color=sns.color_palette('Paired')[8], label=\"Prospective validation set\")\n",
    "sns.lineplot(x=range(0, xlim), y=0.78, ls='--', \n",
    "             color=sns.color_palette('Paired')[4], label=\"External validation set\")\n",
    "\n",
    "plt.xticks(rotation=45, \n",
    "           ticks=range(0, xlim, 2), \n",
    "           labels=[format_quarter(q) for q in df.quarter.cat.categories.astype(str) if q.endswith('1') or q.endswith('3')]);\n",
    "\n",
    "sns.lineplot(df[df.hospital=='RMH'].groupby(df[df.hospital=='RMH'].quarter.cat.codes, observed=False).apply(\n",
    "    lambda x: calculate_auc(x.SH, x.probability, method='pr')), \n",
    "             color=sns.color_palette('Paired')[9], lw=2, label=\"RMH\");\n",
    "\n",
    "sns.lineplot(df[df.hospital=='LRH'].groupby(df[df.hospital=='LRH'].quarter.cat.codes, observed=False).apply(\n",
    "    lambda x: calculate_auc(x.SH, x.probability, method='pr')), \n",
    "             color=sns.color_palette('Paired')[5], lw=2, label=\"LRH\");\n",
    "\n",
    "plt.ylim([0.45, 1.05]);\n",
    "plt.ylabel(\"PR AUC\");\n",
    "plt.savefig(\"../results/Performance by quarter.jpeg\", bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=range(0, xlim), y=0.53, ls='--', \n",
    "             color=sns.color_palette('Set1')[1], label=\"PPV\")\n",
    "sns.lineplot(x=range(0, xlim), y=0.81, ls='--', \n",
    "             color=sns.color_palette('Set1')[2], label=\"Sensitivity\")\n",
    "sns.lineplot(x=range(0, xlim), y=0.99, ls='--', \n",
    "             color=sns.color_palette('Set1')[3], label=\"Specificity\")\n",
    "\n",
    "sns.lineplot(df[df.hospital=='LRH'].groupby(df[df.hospital=='LRH'].quarter.cat.codes, \n",
    "                                            observed=False).apply(lambda x: \n",
    "                                                                  precision_score(x.SH, x.prediction)), \n",
    "             color=sns.color_palette('Set1')[1], lw=2, label=\"PPV\");\n",
    "\n",
    "sns.lineplot(df[df.hospital=='LRH'].groupby(df[df.hospital=='LRH'].quarter.cat.codes, \n",
    "                                            observed=False).apply(lambda x: \n",
    "                                                                  recall_score(x.SH, x.prediction, pos_label=1)), \n",
    "             color=sns.color_palette('Set1')[2], lw=2, label=\"Sensitivity\");\n",
    "\n",
    "sns.lineplot(df[df.hospital=='LRH'].groupby(df[df.hospital=='LRH'].quarter.cat.codes, \n",
    "                                            observed=False).apply(lambda x: \n",
    "                                                                  recall_score(x.SH, x.prediction, pos_label=0)), \n",
    "             color=sns.color_palette('Set1')[3], lw=2, label=\"Specificity\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(df[(df.hospital=='LRH') & (df.quarter=='2021Q4')].SH, \n",
    "             df[(df.hospital=='LRH') & (df.quarter=='2021Q4')].prediction, pos_label=1).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141e8ce",
   "metadata": {},
   "source": [
    "# Reviewed predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae2304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data_filename = \"lvrh_2012_2022\"\n",
    "\n",
    "df = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_predicted.csv\")\n",
    "\n",
    "# Convert to datetime and extract year and quarter\n",
    "df.arrival_date = pd.to_datetime(df.arrival_date)\n",
    "df['year'] = df.arrival_date.dt.year\n",
    "df['quarter'] = df.arrival_date.dt.to_period('Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9bbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewed = pd.read_csv(\"../datasets/\" + unseen_data_filename + \"_reviewed.csv\")\n",
    "df_reviewed.rename(columns={'Revised': 'revised', \n",
    "                            'Recoded_SH': 'recoded_SH', \n",
    "                            'Recoded_SI': 'recoded_SI',\n",
    "                            'Recoded_AOD_OD': 'recoded_AOD_OD', \n",
    "                            'Comment': 'comment'}, \n",
    "                            inplace=True)\n",
    "df = pd.concat([\n",
    "    df, df_reviewed[['revised', 'recoded_SH', 'recoded_SI', 'recoded_AOD_OD', 'comment']]\n",
    "    ], axis=1)\n",
    "\n",
    "# Remove 2022\n",
    "df = df[df.year < 2018].copy()\n",
    "\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717d25a",
   "metadata": {},
   "source": [
    "### Reviewed notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe364f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.for_review.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fa500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.for_review==1].prediction_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.for_review==1].year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96fac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[df.for_review==1].quarter.value_counts() == 6).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b58be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.revised.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['recoded_SH', 'recoded_SI', 'recoded_AOD_OD']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407f26c",
   "metadata": {},
   "source": [
    "### Revised false-positives (Neg pred Pos -> Pos)\n",
    "**Self-harm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9083c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.prediction_class=='FP') & (df.revised==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.prediction_class=='FP') & (df.revised==1)].recoded_SH.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553c4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "6/72, 11/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84559f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.prediction_class=='FP') & (df.revised==1) & (df.recoded_SH==1)].probability.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad89d0",
   "metadata": {},
   "source": [
    "**Suicidal ideation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727629aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.prediction_class=='FP') & (df.revised==1)].recoded_SI.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87cd67",
   "metadata": {},
   "source": [
    "### Revised false-negatives (Pos pred Neg -> Neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.prediction_class=='FN') & (df.revised==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d62322",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[(df.prediction_class=='FN') & (df.revised==1)].recoded_SH.fillna(0)==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "5/72, 12/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617fde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.prediction_class=='FN') & (df.revised==1)].probability.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476316c8",
   "metadata": {},
   "source": [
    "**Plot probability distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79280e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(x='probability', data=df[df.prediction_class=='TN'], \n",
    "#              binwidth=0.035, color=sns.color_palette('Paired')[1], label='TN');\n",
    "# sns.histplot(x='probability', data=df[df.prediction_class=='FN'], \n",
    "#              binwidth=0.035, color=sns.color_palette('Paired')[0], label='FN');\n",
    "# sns.histplot(x='probability', data=df[df.prediction_class=='TP'], \n",
    "#              binwidth=0.035, color=sns.color_palette('Paired')[3], label='TP');\n",
    "# sns.histplot(x='probability', data=df[df.prediction_class=='FP'], \n",
    "#              binwidth=0.035, color=sns.color_palette('Paired')[2], label='FP');\n",
    "\n",
    "\n",
    "# plt.axvline(thresh, 0, 1, color=sns.color_palette('Paired')[5], ls='--', label='Original\\nthreshold');\n",
    "# # plt.axvline(thresh_adj, 0, 1, color=sns.color_palette('Paired')[9], ls='--', label='Adjusted\\nthreshold');\n",
    "# plt.legend();\n",
    "# plt.xlim([0,1]);\n",
    "# plt.ylim([0,2200]);\n",
    "# plt.xlabel(\"Predicted probability\");\n",
    "# plt.ylabel(\"Count\");\n",
    "# # plt.savefig(\"../results/Adjusted threshold.jpeg\", bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aefb3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_outcome'] = \"\"\n",
    "df.loc[(df.prediction_class=='FP') & (df.for_review==1) & (df.recoded_SH!=1), 'review_outcome'] = \"Confirmed FP\"\n",
    "df.loc[(df.prediction_class=='FP') & (df.for_review==1) & (df.revised==1) & (df.recoded_SH==1), 'review_outcome'] = \"Revised TP\"\n",
    "df.loc[(df.prediction_class=='FN') & (df.for_review==1) & (df.revised==0), 'review_outcome'] = \"Confirmed FN\"\n",
    "df.loc[(df.prediction_class=='FN') & (df.for_review==1) & (df.revised==1), 'review_outcome'] = \"Revised TN\"\n",
    "df.review_outcome = df.review_outcome.astype('category').cat.set_categories([\"Confirmed FN\", \"Revised TN\", \n",
    "                                                                             \"Confirmed FP\", \"Revised TP\"])\n",
    "df.review_outcome.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f5362",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "thresh = 0.36\n",
    "\n",
    "sns.histplot(x='probability', data=df[df.review_outcome=='Confirmed FN'], \n",
    "             binwidth=0.035, binrange=(0,thresh), color=sns.color_palette('Paired')[0], label='Confirmed FN');\n",
    "sns.histplot(x='probability', data=df[df.review_outcome=='Revised TN'], \n",
    "             binwidth=0.035, binrange=(0,thresh), color=sns.color_palette('Paired')[1], label='Revised TN');\n",
    "sns.histplot(x='probability', data=df[df.review_outcome=='Confirmed FP'], \n",
    "             binwidth=0.035, binrange=(thresh,1), color=sns.color_palette('Paired')[2], label='Confirmed FP');\n",
    "sns.histplot(x='probability', data=df[df.review_outcome=='Revised TP'], \n",
    "             binwidth=0.035, binrange=(thresh,1), color=sns.color_palette('Paired')[3], label='Revised TP');\n",
    "\n",
    "plt.legend();\n",
    "plt.xlim([0,1]);\n",
    "plt.xlabel(\"Predicted probability\");\n",
    "plt.ylabel(\"Count\");\n",
    "plt.savefig(\"../results/Review results.jpeg\", bbox_inches='tight', dpi=300);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470c5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classification\n",
    "evaluate_classification(df.SH, df.prediction, filename=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed9213",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.prediction_class.value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31780c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPV\n",
    "fp2tp = counts.FP * 6/72\n",
    "print(\"%d notes will be reviewed as true positive\" % fp2tp)\n",
    "(counts.TP + fp2tp) / (counts.TP + counts.FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e398c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity\n",
    "fn2tn = counts.FN * 5/72\n",
    "print(\"%d notes will be reviewed as true negative\" % fn2tn)\n",
    "(counts.TP + fp2tp) / (counts.TP + fp2tp + counts.FN - fn2tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e932de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity\n",
    "(counts.TN + fn2tn) / (counts.TN + counts.FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc79334",
   "metadata": {},
   "outputs": [],
   "source": [
    "83 - (83-57)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84a290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-harm-triage-notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
